{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "3d460717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import time\n",
    "from sklearn.datasets import make_classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487a7d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/train.csv\",\n",
    "                    index_col=\"PassengerId\" \n",
    "                   ).drop(columns=[\"Name\", \"Ticket\"] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7eacdc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plots(data: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Display various plots based on Titanic dataset columns to visualize relationships \n",
    "    between features like Age, Pclass, Embarked, etc., and survival status.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Titanic dataset containing relevant columns.\n",
    "    \"\"\"\n",
    "    required_columns = ['Age', 'Pclass', 'Survived', 'Sex', 'SibSp', 'Parch', 'Embarked', 'Cabin']\n",
    "    missing_cols = [col for col in required_columns if col not in data.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns in data: {missing_cols}\")\n",
    "\n",
    "    px.histogram(data, x=\"Age\", color=\"Survived\", title=\"Age Distribution by Survival\").show()\n",
    "\n",
    "    px.histogram(data, x=\"Pclass\", color=\"Survived\", title=\"Pclass Distribution by Survival\").show()\n",
    "\n",
    "    px.histogram(data, x=\"Survived\", color=\"Sex\", title=\"Survival Count by Sex\").show()\n",
    "\n",
    "    px.violin(\n",
    "        data, x=\"Pclass\", y=\"Age\", color=\"Survived\",\n",
    "        box=True, points=\"all\",\n",
    "        title=\"Age Distribution by Pclass and Survival\"\n",
    "    ).show()\n",
    "\n",
    "    data = data.copy()\n",
    "    data['family_size'] = data[\"SibSp\"] + data[\"Parch\"] + 1\n",
    "\n",
    "    px.histogram(\n",
    "        data, x=\"family_size\", color=\"Survived\", title=\"Family Size Distribution by Survival\"\n",
    "    ).show()\n",
    "\n",
    "    px.histogram(\n",
    "        data, x=\"Embarked\", color=\"Survived\",\n",
    "        histnorm='percent', title=\"Embarkation Port Distribution by Survival (in %)\"\n",
    "    ).show()\n",
    "\n",
    "    data['Deck'] = data['Cabin'].astype(str).str[0]\n",
    "\n",
    "    px.histogram(\n",
    "        data, x=\"Deck\", color=\"Survived\", title=\"Cabin Deck Distribution by Survival\"\n",
    "    ).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e55089d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(dataframe: pd.DataFrame, method: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean DataFrame using specified methods.\n",
    "    \n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): Input DataFrame. It remains unmodified.\n",
    "        method (str): Cleaning method for 'Age'. Options: ['dropna', 'median', 'interpolate'].\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: A cleaned DataFrame with modified 'Age', 'Embarked', and 'Cabin' columns.\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If an invalid method is provided.\n",
    "    \"\"\"\n",
    "    if method not in ['dropna', 'median', 'interpolate']:\n",
    "        raise ValueError(f\"Invalid method: {method}. Use 'dropna', 'median', or 'interpolate'.\")\n",
    "\n",
    "    if method == \"dropna\":\n",
    "        return dataframe.dropna(subset=['Age'])\n",
    "\n",
    "    cleaned_data = dataframe.copy()\n",
    "    \n",
    "    for col in ['Embarked', 'Deck']:\n",
    "        if col in cleaned_data.columns:\n",
    "            cleaned_data[col] = cleaned_data[col].fillna('Unknown')\n",
    "\n",
    "    if method == \"median\":\n",
    "        if 'Age' in cleaned_data.columns:\n",
    "            imputer = SimpleImputer(strategy=\"median\")\n",
    "            cleaned_data['Age'] = imputer.fit_transform(cleaned_data[['Age']])\n",
    "        return cleaned_data\n",
    "\n",
    "    if method == \"interpolate\":\n",
    "        if 'Age' in cleaned_data.columns:\n",
    "            cleaned_data['Age'] = cleaned_data['Age'].interpolate()\n",
    "        return cleaned_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db9670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_deck(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Adding a deck column\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): Input DataFrame. It remains unmodified.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Output DataFrame. It has the 'Deck' column but doesn't have the 'Cabin' column\n",
    "    \"\"\"\n",
    "    new_df = dataframe.copy()\n",
    "    new_df['Deck'] = new_df['Cabin'].apply(lambda x: str(x)[0] if pd.notnull(x) else np.nan)\n",
    "    new_df.drop(columns=['Cabin'], inplace=True)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cf444f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(dataframe: pd.DataFrame, drop_unkown: bool = True) -> pd.DataFrame:\n",
    "    \n",
    "    \"\"\"\n",
    "    Encodes categorical columns in a DataFrame using one-hot encoding.\n",
    "\n",
    "    This function identifies all columns of type 'object', applies one-hot encoding \n",
    "    to them using sklearn's OneHotEncoder, and returns a new DataFrame with the \n",
    "    encoded columns concatenated to the original numerical columns.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): The input DataFrame containing categorical and/or numerical features.\n",
    "        drop_unkown (bool): Yes if the encoder drop unkowns, No otherwise\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with categorical columns one-hot encoded and original categorical columns removed.\n",
    "    \"\"\"\n",
    "\n",
    "    cat_columns = list(dataframe.select_dtypes(include='object').columns)\n",
    "    \n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    encoder.fit(dataframe[cat_columns])\n",
    "    \n",
    "    encoded_array = encoder.transform(dataframe[cat_columns])\n",
    "    \n",
    "    encoded_columns = encoder.get_feature_names_out(cat_columns)\n",
    "    \n",
    "    encoded_df = pd.DataFrame(encoded_array, columns=encoded_columns, index=dataframe.index)\n",
    "    \n",
    "    non_cat_data = dataframe.drop(columns=cat_columns)\n",
    "    \n",
    "    final_df = pd.concat([non_cat_data, encoded_df], axis=1)\n",
    "    if drop_unkown : \n",
    "        return final_df\n",
    "    return final_df.drop(columns=['Deck_Unknown', 'Embarked_Unknown'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748ab115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data (dataframe: pd.DataFrame, val_size: float = 0.25) -> list[pd.DataFrame] :\n",
    "    \"\"\"Spliting data to Training and Valuation data\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): Input DataFrame. It remains unmodified.\n",
    "        val_size (float, optional): Test size. Defaults to 0.25.\n",
    "\n",
    "    Returns:\n",
    "        list[pd.DataFrame]: List of the training and the validation data sets\n",
    "    \"\"\"\n",
    "    X = dataframe[dataframe.columns[1:]]\n",
    "    y = dataframe[dataframe.columns[0]]\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=val_size, random_state=42)\n",
    "    return X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf78c68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_model_training (X_train: pd.DataFrame , y_train: pd.DataFrame, MAXDEPTH: int) -> DecisionTreeClassifier:\n",
    "    \"\"\"Training a tree model\n",
    "\n",
    "    Args:\n",
    "        X_train (pd.DataFrame): The input X we will train our model on\n",
    "        y_train (pd.DataFrame): The input Y we will train our model on\n",
    "        MAXDEPTH (int): The max depth of the tree\n",
    "\n",
    "    Returns:\n",
    "        DecisionTreeClassifier: Trained classifier Tree model \n",
    "    \"\"\"\n",
    "    model = DecisionTreeClassifier(max_depth=MAXDEPTH, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "5d0f8070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model: DecisionTreeClassifier,\n",
    "                    X_train:pd.DataFrame , \n",
    "                    X_val: pd.DataFrame,\n",
    "                    y_train: pd.DataFrame,\n",
    "                    y_val:pd.DataFrame,\n",
    "                    printing: bool=False) -> list[float] : \n",
    "    \n",
    "    \"\"\"Evaluating the model on training data and validation data, and optiomally prints out the numbers \n",
    "\n",
    "    Args:\n",
    "        model (DecisionTreeClassifier): _description_\n",
    "        X_train (pd.DataFrame): The train input X \n",
    "        X_val (pd.DataFrame): The validation input Y\n",
    "        y_train (pd.DataFrame): The train input Y \n",
    "        y_val (pd.DataFrame): The validation input Y\n",
    "        printing (bool, optional): Wethere to print out the accuarcies. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "         list[flaot]: the accuarcies of the model\n",
    "    \"\"\"\n",
    "    R1 = model.score(X_train, y_train)\n",
    "    R2 = model.score(X_val, y_val)\n",
    "    if printing :\n",
    "        print(f\"the accuarcy of the model on trained data is {round(R1*100,1)}%\")\n",
    "        print(f\"the accuarcy of the model on validation data is {round(R2*100,1)}%\")\n",
    "    return R1,R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6a60bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_tree(model: DecisionTreeClassifier, \n",
    "                    X_train: pd.DataFrame,\n",
    "                    FIGSIZE: tuple = (80,20),\n",
    "                    depth: int = 3) -> None:\n",
    "    \"\"\"visualizing the tree model\n",
    "\n",
    "    Args:\n",
    "        model (DecisionTreeClassifier): the model\n",
    "        X_train (pd.DataFrame): The input data (to use columns from)\n",
    "        FIGSIZE (tuple, optional): Figure Size. Defaults to (80,20).\n",
    "        depth (int, optional): How much depth should be showed. Defaults to 3.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=FIGSIZE)\n",
    "    plot_tree(model, feature_names=X_train.columns, max_depth= depth , filled= True, class_names=['No', 'Yes']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "ffb08b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_tree_depth(X_train: pd.DataFrame,\n",
    "                             X_val: pd.DataFrame,\n",
    "                             y_train: pd.DataFrame,\n",
    "                             y_val: pd.DataFrame,\n",
    "                             MAX_DEPTH: int,\n",
    "                             visualise: bool=False) -> list[list[tuple], int]:\n",
    "    \"\"\"Finding the optimal maximum depth for a tree classifiel model\n",
    "\n",
    "    Args:\n",
    "        X_train (pd.DataFrame): Input training X data\n",
    "        X_val (pd.DataFrame): Input validation X data\n",
    "        y_train (pd.DataFrame): Input training y data\n",
    "        y_val (pd.DataFrame): Input validation y data\n",
    "        MAX_DEPTH (int): maximum depth of the tree\n",
    "        visualise (bool, optional): whether to visualise the accuracies accross multiple depths. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        list[list[tuple], int]: outputs the accuracies and the best found depth \n",
    "    \"\"\"\n",
    "\n",
    "    accuracies = []\n",
    "    best_depth = 1\n",
    "    best_val_acc = 0\n",
    "\n",
    "    for depth in range(1, MAX_DEPTH + 1):\n",
    "        model = tree_model_training(X_train, y_train, MAXDEPTH=depth)\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "\n",
    "        train_acc = accuracy_score(y_train, y_train_pred)\n",
    "        val_acc = accuracy_score(y_val, y_val_pred)\n",
    "        accuracies.append((train_acc, val_acc))\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_depth = depth\n",
    "\n",
    "    if visualise:\n",
    "        train_accuracies = [acc[0] for acc in accuracies]\n",
    "        val_accuracies = [acc[1] for acc in accuracies]\n",
    "        depths = list(range(1, MAX_DEPTH + 1))\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(depths, train_accuracies, label='Training Accuracy', marker='o')\n",
    "        plt.plot(depths, val_accuracies, label='Validation Accuracy', marker='s')\n",
    "        plt.axvline(x=best_depth, color='r', linestyle='--', label=f'Best Depth: {best_depth}')\n",
    "        plt.title('Decision Tree Accuracy vs Max Depth')\n",
    "        plt.xlabel('Max Depth')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return accuracies, best_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "30710c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_train (X_train: pd.DataFrame,\n",
    "                        y_train: pd.DataFrame,\n",
    "                        n_trees:int = 1,\n",
    "                        maxdepth = 4,\n",
    "                        maxfeatures = \"log2\"\n",
    "                        ) :\n",
    "    model = RandomForestClassifier(n_jobs=-1,\n",
    "                                random_state=42,\n",
    "                                n_estimators= n_trees,\n",
    "                                max_depth=maxdepth,\n",
    "                                max_features=maxfeatures)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "fd239e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8340807174887892"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = encode_data(clean_data(data_deck(data), \"median\"))\n",
    "X_train, X_val, y_train, y_val = split_data(temp, 0.25)\n",
    "trained_model = tree_model_training(X_train, y_train, \n",
    "                                    MAXDEPTH=14)\n",
    "\n",
    "new_trained_model2 = random_forest_train(X_train, y_train, n_trees=1, maxdepth = 4)\n",
    "acc2 = evaluate_model(new_trained_model2, X_train, X_val, y_train, y_val,printing=False)[1]\n",
    "acc2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "427e3ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_different_variables(model, X_train, X_val, y_train, y_val) :\n",
    "    n_trees = np.arange(1,13)\n",
    "    maxdepths = np.arange(1,16)\n",
    "    \n",
    "    results = np.zeros((len(n_trees), len(maxdepths)))\n",
    "\n",
    "    for i, ntree in enumerate(n_trees):\n",
    "        for j, maxdepth in enumerate(maxdepths):\n",
    "            model = random_forest_train(X_train, y_train, n_trees=ntree, maxdepth=maxdepth)\n",
    "            acc = evaluate_model(model, X_train, X_val, y_train, y_val, printing=False)[1]\n",
    "            results[i, j] = acc\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.heatmap(results, xticklabels=maxdepths, yticklabels=n_trees, cmap='viridis')\n",
    "    plt.xlabel('Max Depth')\n",
    "    plt.ylabel('N_trees')\n",
    "    plt.title('Validation Accuracy Heatmap')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5bbe08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data for example...\n",
      "Splitting data...\n",
      "Train set size: 1050, Validation set size: 450\n",
      "Starting hyperparameter analysis for 96 combinations...\n",
      "Running combination 1/96: {'n_estimators': 50, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9419, Val Acc: 0.8689, Time: 0.08s\n",
      "Running combination 2/96: {'n_estimators': 50, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9419, Val Acc: 0.8733, Time: 0.07s\n",
      "Running combination 3/96: {'n_estimators': 50, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 4, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9362, Val Acc: 0.8644, Time: 0.07s\n",
      "Running combination 4/96: {'n_estimators': 50, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 4, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9314, Val Acc: 0.8711, Time: 0.07s\n",
      "Running combination 5/96: {'n_estimators': 50, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 8, 'min_samples_leaf': 1, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9390, Val Acc: 0.8622, Time: 0.07s\n",
      "Running combination 6/96: {'n_estimators': 50, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 8, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9390, Val Acc: 0.8689, Time: 0.07s\n",
      "Running combination 7/96: {'n_estimators': 50, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 8, 'min_samples_leaf': 4, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9362, Val Acc: 0.8644, Time: 0.07s\n",
      "Running combination 8/96: {'n_estimators': 50, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 8, 'min_samples_leaf': 4, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9314, Val Acc: 0.8711, Time: 0.07s\n",
      "Running combination 9/96: {'n_estimators': 50, 'max_depth': 5, 'max_features': 0.6, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9429, Val Acc: 0.8667, Time: 0.10s\n",
      "Running combination 10/96: {'n_estimators': 50, 'max_depth': 5, 'max_features': 0.6, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9390, Val Acc: 0.8622, Time: 0.10s\n",
      "Running combination 11/96: {'n_estimators': 50, 'max_depth': 5, 'max_features': 0.6, 'min_samples_split': 2, 'min_samples_leaf': 4, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9343, Val Acc: 0.8778, Time: 0.09s\n",
      "Running combination 12/96: {'n_estimators': 50, 'max_depth': 5, 'max_features': 0.6, 'min_samples_split': 2, 'min_samples_leaf': 4, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9305, Val Acc: 0.8600, Time: 0.11s\n",
      "Running combination 13/96: {'n_estimators': 50, 'max_depth': 5, 'max_features': 0.6, 'min_samples_split': 8, 'min_samples_leaf': 1, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9400, Val Acc: 0.8822, Time: 0.08s\n",
      "Running combination 14/96: {'n_estimators': 50, 'max_depth': 5, 'max_features': 0.6, 'min_samples_split': 8, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9371, Val Acc: 0.8689, Time: 0.11s\n",
      "Running combination 15/96: {'n_estimators': 50, 'max_depth': 5, 'max_features': 0.6, 'min_samples_split': 8, 'min_samples_leaf': 4, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9343, Val Acc: 0.8778, Time: 0.09s\n",
      "Running combination 16/96: {'n_estimators': 50, 'max_depth': 5, 'max_features': 0.6, 'min_samples_split': 8, 'min_samples_leaf': 4, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9305, Val Acc: 0.8600, Time: 0.10s\n",
      "Running combination 17/96: {'n_estimators': 50, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9981, Val Acc: 0.8956, Time: 0.07s\n",
      "Running combination 18/96: {'n_estimators': 50, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 1.0000, Val Acc: 0.8889, Time: 0.08s\n",
      "Running combination 19/96: {'n_estimators': 50, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 4, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9733, Val Acc: 0.8889, Time: 0.07s\n",
      "Running combination 20/96: {'n_estimators': 50, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 4, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9800, Val Acc: 0.8867, Time: 0.08s\n",
      "Running combination 21/96: {'n_estimators': 50, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 8, 'min_samples_leaf': 1, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9924, Val Acc: 0.8978, Time: 0.07s\n",
      "Running combination 22/96: {'n_estimators': 50, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 8, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9905, Val Acc: 0.8756, Time: 0.07s\n",
      "Running combination 23/96: {'n_estimators': 50, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 8, 'min_samples_leaf': 4, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9733, Val Acc: 0.8889, Time: 0.07s\n",
      "Running combination 24/96: {'n_estimators': 50, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 8, 'min_samples_leaf': 4, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9800, Val Acc: 0.8867, Time: 0.07s\n",
      "Running combination 25/96: {'n_estimators': 50, 'max_depth': 10, 'max_features': 0.6, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9971, Val Acc: 0.9000, Time: 0.11s\n",
      "Running combination 26/96: {'n_estimators': 50, 'max_depth': 10, 'max_features': 0.6, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 1.0000, Val Acc: 0.8889, Time: 0.11s\n",
      "Running combination 27/96: {'n_estimators': 50, 'max_depth': 10, 'max_features': 0.6, 'min_samples_split': 2, 'min_samples_leaf': 4, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9790, Val Acc: 0.8956, Time: 0.10s\n",
      "Running combination 28/96: {'n_estimators': 50, 'max_depth': 10, 'max_features': 0.6, 'min_samples_split': 2, 'min_samples_leaf': 4, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9829, Val Acc: 0.8889, Time: 0.11s\n",
      "Running combination 29/96: {'n_estimators': 50, 'max_depth': 10, 'max_features': 0.6, 'min_samples_split': 8, 'min_samples_leaf': 1, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9924, Val Acc: 0.8867, Time: 0.10s\n",
      "Running combination 30/96: {'n_estimators': 50, 'max_depth': 10, 'max_features': 0.6, 'min_samples_split': 8, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9952, Val Acc: 0.8867, Time: 0.12s\n",
      "Running combination 31/96: {'n_estimators': 50, 'max_depth': 10, 'max_features': 0.6, 'min_samples_split': 8, 'min_samples_leaf': 4, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9790, Val Acc: 0.8956, Time: 0.10s\n",
      "Running combination 32/96: {'n_estimators': 50, 'max_depth': 10, 'max_features': 0.6, 'min_samples_split': 8, 'min_samples_leaf': 4, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9829, Val Acc: 0.8889, Time: 0.12s\n",
      "Running combination 33/96: {'n_estimators': 50, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 1.0000, Val Acc: 0.9000, Time: 0.08s\n",
      "Running combination 34/96: {'n_estimators': 50, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 1.0000, Val Acc: 0.8889, Time: 0.08s\n",
      "Running combination 35/96: {'n_estimators': 50, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 4, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9743, Val Acc: 0.8889, Time: 0.07s\n",
      "Running combination 36/96: {'n_estimators': 50, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 4, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9838, Val Acc: 0.8978, Time: 0.08s\n",
      "Running combination 37/96: {'n_estimators': 50, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 8, 'min_samples_leaf': 1, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9971, Val Acc: 0.8867, Time: 0.07s\n",
      "Running combination 38/96: {'n_estimators': 50, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 8, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9924, Val Acc: 0.8911, Time: 0.08s\n",
      "Running combination 39/96: {'n_estimators': 50, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 8, 'min_samples_leaf': 4, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9743, Val Acc: 0.8889, Time: 0.08s\n",
      "Running combination 40/96: {'n_estimators': 50, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 8, 'min_samples_leaf': 4, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9838, Val Acc: 0.8978, Time: 0.08s\n",
      "Running combination 41/96: {'n_estimators': 50, 'max_depth': None, 'max_features': 0.6, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 1.0000, Val Acc: 0.9000, Time: 0.11s\n",
      "Running combination 42/96: {'n_estimators': 50, 'max_depth': None, 'max_features': 0.6, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 1.0000, Val Acc: 0.8822, Time: 0.12s\n",
      "Running combination 43/96: {'n_estimators': 50, 'max_depth': None, 'max_features': 0.6, 'min_samples_split': 2, 'min_samples_leaf': 4, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9781, Val Acc: 0.9000, Time: 0.09s\n",
      "Running combination 44/96: {'n_estimators': 50, 'max_depth': None, 'max_features': 0.6, 'min_samples_split': 2, 'min_samples_leaf': 4, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9848, Val Acc: 0.8889, Time: 0.11s\n",
      "Running combination 45/96: {'n_estimators': 50, 'max_depth': None, 'max_features': 0.6, 'min_samples_split': 8, 'min_samples_leaf': 1, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9962, Val Acc: 0.8911, Time: 0.11s\n",
      "Running combination 46/96: {'n_estimators': 50, 'max_depth': None, 'max_features': 0.6, 'min_samples_split': 8, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9971, Val Acc: 0.8956, Time: 0.12s\n",
      "Running combination 47/96: {'n_estimators': 50, 'max_depth': None, 'max_features': 0.6, 'min_samples_split': 8, 'min_samples_leaf': 4, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9781, Val Acc: 0.9000, Time: 0.10s\n",
      "Running combination 48/96: {'n_estimators': 50, 'max_depth': None, 'max_features': 0.6, 'min_samples_split': 8, 'min_samples_leaf': 4, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9848, Val Acc: 0.8889, Time: 0.11s\n",
      "Running combination 49/96: {'n_estimators': 100, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9438, Val Acc: 0.8756, Time: 0.13s\n",
      "Running combination 50/96: {'n_estimators': 100, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9438, Val Acc: 0.8733, Time: 0.13s\n",
      "Running combination 51/96: {'n_estimators': 100, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 4, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9371, Val Acc: 0.8689, Time: 0.12s\n",
      "Running combination 52/96: {'n_estimators': 100, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 4, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9267, Val Acc: 0.8733, Time: 0.14s\n",
      "Running combination 53/96: {'n_estimators': 100, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 8, 'min_samples_leaf': 1, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9410, Val Acc: 0.8711, Time: 0.13s\n",
      "Running combination 54/96: {'n_estimators': 100, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 8, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9371, Val Acc: 0.8733, Time: 0.14s\n",
      "Running combination 55/96: {'n_estimators': 100, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 8, 'min_samples_leaf': 4, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9371, Val Acc: 0.8689, Time: 0.13s\n",
      "Running combination 56/96: {'n_estimators': 100, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 8, 'min_samples_leaf': 4, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9267, Val Acc: 0.8733, Time: 0.13s\n",
      "Running combination 57/96: {'n_estimators': 100, 'max_depth': 5, 'max_features': 0.6, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9390, Val Acc: 0.8733, Time: 0.16s\n",
      "Running combination 58/96: {'n_estimators': 100, 'max_depth': 5, 'max_features': 0.6, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9429, Val Acc: 0.8711, Time: 0.18s\n",
      "Running combination 59/96: {'n_estimators': 100, 'max_depth': 5, 'max_features': 0.6, 'min_samples_split': 2, 'min_samples_leaf': 4, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9314, Val Acc: 0.8778, Time: 0.16s\n",
      "Running combination 60/96: {'n_estimators': 100, 'max_depth': 5, 'max_features': 0.6, 'min_samples_split': 2, 'min_samples_leaf': 4, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9362, Val Acc: 0.8778, Time: 0.18s\n",
      "Running combination 61/96: {'n_estimators': 100, 'max_depth': 5, 'max_features': 0.6, 'min_samples_split': 8, 'min_samples_leaf': 1, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9371, Val Acc: 0.8844, Time: 0.17s\n",
      "Running combination 62/96: {'n_estimators': 100, 'max_depth': 5, 'max_features': 0.6, 'min_samples_split': 8, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9429, Val Acc: 0.8667, Time: 0.18s\n",
      "Running combination 63/96: {'n_estimators': 100, 'max_depth': 5, 'max_features': 0.6, 'min_samples_split': 8, 'min_samples_leaf': 4, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9314, Val Acc: 0.8778, Time: 0.15s\n",
      "Running combination 64/96: {'n_estimators': 100, 'max_depth': 5, 'max_features': 0.6, 'min_samples_split': 8, 'min_samples_leaf': 4, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9362, Val Acc: 0.8778, Time: 0.18s\n",
      "Running combination 65/96: {'n_estimators': 100, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9981, Val Acc: 0.8956, Time: 0.13s\n",
      "Running combination 66/96: {'n_estimators': 100, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9990, Val Acc: 0.8911, Time: 0.14s\n",
      "Running combination 67/96: {'n_estimators': 100, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 4, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9800, Val Acc: 0.9022, Time: 0.14s\n",
      "Running combination 68/96: {'n_estimators': 100, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 4, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9829, Val Acc: 0.8956, Time: 0.15s\n",
      "Running combination 69/96: {'n_estimators': 100, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 8, 'min_samples_leaf': 1, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9914, Val Acc: 0.8933, Time: 0.14s\n",
      "Running combination 70/96: {'n_estimators': 100, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 8, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9914, Val Acc: 0.8956, Time: 0.15s\n",
      "Running combination 71/96: {'n_estimators': 100, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 8, 'min_samples_leaf': 4, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9800, Val Acc: 0.9022, Time: 0.12s\n",
      "Running combination 72/96: {'n_estimators': 100, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 8, 'min_samples_leaf': 4, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9829, Val Acc: 0.8956, Time: 0.15s\n",
      "Running combination 73/96: {'n_estimators': 100, 'max_depth': 10, 'max_features': 0.6, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9971, Val Acc: 0.9022, Time: 0.18s\n",
      "Running combination 74/96: {'n_estimators': 100, 'max_depth': 10, 'max_features': 0.6, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 1.0000, Val Acc: 0.8867, Time: 0.21s\n",
      "Running combination 75/96: {'n_estimators': 100, 'max_depth': 10, 'max_features': 0.6, 'min_samples_split': 2, 'min_samples_leaf': 4, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9781, Val Acc: 0.9000, Time: 0.18s\n",
      "Running combination 76/96: {'n_estimators': 100, 'max_depth': 10, 'max_features': 0.6, 'min_samples_split': 2, 'min_samples_leaf': 4, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9848, Val Acc: 0.8889, Time: 0.21s\n",
      "Running combination 77/96: {'n_estimators': 100, 'max_depth': 10, 'max_features': 0.6, 'min_samples_split': 8, 'min_samples_leaf': 1, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9933, Val Acc: 0.9022, Time: 0.18s\n",
      "Running combination 78/96: {'n_estimators': 100, 'max_depth': 10, 'max_features': 0.6, 'min_samples_split': 8, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9933, Val Acc: 0.8933, Time: 0.20s\n",
      "Running combination 79/96: {'n_estimators': 100, 'max_depth': 10, 'max_features': 0.6, 'min_samples_split': 8, 'min_samples_leaf': 4, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9781, Val Acc: 0.9000, Time: 0.17s\n",
      "Running combination 80/96: {'n_estimators': 100, 'max_depth': 10, 'max_features': 0.6, 'min_samples_split': 8, 'min_samples_leaf': 4, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9848, Val Acc: 0.8889, Time: 0.20s\n",
      "Running combination 81/96: {'n_estimators': 100, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 1.0000, Val Acc: 0.9000, Time: 0.14s\n",
      "Running combination 82/96: {'n_estimators': 100, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 1.0000, Val Acc: 0.8933, Time: 0.14s\n",
      "Running combination 83/96: {'n_estimators': 100, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 4, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9800, Val Acc: 0.8978, Time: 0.13s\n",
      "Running combination 84/96: {'n_estimators': 100, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 4, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9838, Val Acc: 0.9000, Time: 0.14s\n",
      "Running combination 85/96: {'n_estimators': 100, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 8, 'min_samples_leaf': 1, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9962, Val Acc: 0.9000, Time: 0.13s\n",
      "Running combination 86/96: {'n_estimators': 100, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 8, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9952, Val Acc: 0.9000, Time: 0.15s\n",
      "Running combination 87/96: {'n_estimators': 100, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 8, 'min_samples_leaf': 4, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9800, Val Acc: 0.8978, Time: 0.13s\n",
      "Running combination 88/96: {'n_estimators': 100, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 8, 'min_samples_leaf': 4, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9838, Val Acc: 0.9000, Time: 0.15s\n",
      "Running combination 89/96: {'n_estimators': 100, 'max_depth': None, 'max_features': 0.6, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 1.0000, Val Acc: 0.9044, Time: 0.19s\n",
      "Running combination 90/96: {'n_estimators': 100, 'max_depth': None, 'max_features': 0.6, 'min_samples_split': 2, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 1.0000, Val Acc: 0.8889, Time: 0.21s\n",
      "Running combination 91/96: {'n_estimators': 100, 'max_depth': None, 'max_features': 0.6, 'min_samples_split': 2, 'min_samples_leaf': 4, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9790, Val Acc: 0.8956, Time: 0.18s\n",
      "Running combination 92/96: {'n_estimators': 100, 'max_depth': None, 'max_features': 0.6, 'min_samples_split': 2, 'min_samples_leaf': 4, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9838, Val Acc: 0.8867, Time: 0.21s\n",
      "Running combination 93/96: {'n_estimators': 100, 'max_depth': None, 'max_features': 0.6, 'min_samples_split': 8, 'min_samples_leaf': 1, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9943, Val Acc: 0.9044, Time: 0.19s\n",
      "Running combination 94/96: {'n_estimators': 100, 'max_depth': None, 'max_features': 0.6, 'min_samples_split': 8, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9962, Val Acc: 0.8978, Time: 0.22s\n",
      "Running combination 95/96: {'n_estimators': 100, 'max_depth': None, 'max_features': 0.6, 'min_samples_split': 8, 'min_samples_leaf': 4, 'criterion': 'gini', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9790, Val Acc: 0.8956, Time: 0.17s\n",
      "Running combination 96/96: {'n_estimators': 100, 'max_depth': None, 'max_features': 0.6, 'min_samples_split': 8, 'min_samples_leaf': 4, 'criterion': 'entropy', 'bootstrap': True}\n",
      "  -> Train Acc: 0.9838, Val Acc: 0.8867, Time: 0.20s\n",
      "\n",
      "Hyperparameter analysis complete.\n",
      "\n",
      "--- Hyperparameter Analysis Results ---\n",
      "   n_estimators  max_depth max_features  min_samples_split  min_samples_leaf  \\\n",
      "0           100        NaN          0.6                  2                 1   \n",
      "1           100        NaN          0.6                  8                 1   \n",
      "2           100       10.0         sqrt                  2                 4   \n",
      "3           100       10.0         sqrt                  8                 4   \n",
      "4           100       10.0          0.6                  8                 1   \n",
      "5           100       10.0          0.6                  2                 1   \n",
      "6            50       10.0          0.6                  2                 1   \n",
      "7           100        NaN         sqrt                  8                 1   \n",
      "8            50        NaN          0.6                  8                 4   \n",
      "9            50        NaN         sqrt                  2                 1   \n",
      "\n",
      "  criterion  bootstrap  train_accuracy  val_accuracy  train_time_s  \n",
      "0      gini       True         1.00000       0.90444         0.188  \n",
      "1      gini       True         0.99429       0.90444         0.189  \n",
      "2      gini       True         0.98000       0.90222         0.135  \n",
      "3      gini       True         0.98000       0.90222         0.125  \n",
      "4      gini       True         0.99333       0.90222         0.184  \n",
      "5      gini       True         0.99714       0.90222         0.181  \n",
      "6      gini       True         0.99714       0.90000         0.111  \n",
      "7   entropy       True         0.99524       0.90000         0.146  \n",
      "8      gini       True         0.97810       0.90000         0.097  \n",
      "9      gini       True         1.00000       0.90000         0.084  \n",
      "\n",
      "--- Best Hyperparameter Combination Found ---\n",
      "n_estimators             100\n",
      "max_depth                NaN\n",
      "max_features             0.6\n",
      "min_samples_split          2\n",
      "min_samples_leaf           1\n",
      "criterion               gini\n",
      "bootstrap               True\n",
      "train_accuracy           1.0\n",
      "val_accuracy         0.90444\n",
      "train_time_s           0.188\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def analyze_random_forest_hyperparameters(\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series or pd.DataFrame,\n",
    "    X_val: pd.DataFrame,\n",
    "    y_val: pd.Series or pd.DataFrame,\n",
    "    n_estimators_list: list = [50, 100, 200],\n",
    "    max_depth_list: list = [4, 8, 12, None],\n",
    "    max_features_list: list = ['sqrt', 'log2', 0.5],\n",
    "    min_samples_split_list: list = [2, 5, 10],\n",
    "    min_samples_leaf_list: list = [1, 3, 5],\n",
    "    criterion_list: list = ['gini', 'entropy'],\n",
    "    bootstrap_list: list = [True], # Usually True for RF, but can test False\n",
    "    n_jobs: int = -1,\n",
    "    random_state: int = 42\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Trains and evaluates RandomForestClassifiers with various hyperparameter combinations.\n",
    "\n",
    "    This function iterates through all combinations of the provided hyperparameter lists,\n",
    "    trains a RandomForestClassifier for each combination on the training data,\n",
    "    evaluates its performance (accuracy) on both the training and validation sets,\n",
    "    and measures the training time.\n",
    "\n",
    "    Args:\n",
    "        X_train: Training features DataFrame.\n",
    "        y_train: Training target variable Series or DataFrame.\n",
    "        X_val: Validation features DataFrame.\n",
    "        y_val: Validation target variable Series or DataFrame.\n",
    "        n_estimators_list: List of n_estimators values to try.\n",
    "        max_depth_list: List of max_depth values to try (can include None).\n",
    "        max_features_list: List of max_features values to try ('sqrt', 'log2', float, int).\n",
    "        min_samples_split_list: List of min_samples_split values to try (int >= 2 or float).\n",
    "        min_samples_leaf_list: List of min_samples_leaf values to try (int >= 1 or float).\n",
    "        criterion_list: List of criterion values to try ('gini', 'entropy', 'log_loss').\n",
    "        bootstrap_list: List of boolean values for the bootstrap parameter.\n",
    "        n_jobs: Number of jobs to run in parallel for fit. -1 means using all processors.\n",
    "        random_state: Controls randomness for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame containing the results of each hyperparameter combination,\n",
    "        sorted by validation accuracy in descending order. Columns include the tested\n",
    "        hyperparameters, training accuracy, validation accuracy, and training time.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    if isinstance(y_train, pd.DataFrame):\n",
    "         y_train_ravel = y_train.values.ravel()\n",
    "         y_train_ravel = y_train\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': n_estimators_list,\n",
    "        'max_depth': max_depth_list,\n",
    "        'max_features': max_features_list,\n",
    "        'min_samples_split': min_samples_split_list,\n",
    "        'min_samples_leaf': min_samples_leaf_list,\n",
    "        'criterion': criterion_list,\n",
    "        'bootstrap': bootstrap_list\n",
    "    }\n",
    "\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    param_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "    total_combinations = len(param_combinations)\n",
    "    print(f\"Starting hyperparameter analysis for {total_combinations} combinations...\")\n",
    "\n",
    "    for i, params in enumerate(param_combinations):\n",
    "        print(f\"Running combination {i+1}/{total_combinations}: {params}\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        model = RandomForestClassifier(\n",
    "            **params,  \n",
    "            n_jobs=n_jobs,\n",
    "            random_state=random_state\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train_ravel)\n",
    "        end_time = time.time()\n",
    "        train_time = end_time - start_time\n",
    "\n",
    "        # Evaluate on training data\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        train_accuracy = accuracy_score(y_train_ravel, y_train_pred)\n",
    "\n",
    "        # Evaluate on validation data\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "        # Store results - start with the parameters and add metrics\n",
    "        result_entry = params.copy()\n",
    "        result_entry['train_accuracy'] = round(train_accuracy, 5)\n",
    "        result_entry['val_accuracy'] = round(val_accuracy, 5)\n",
    "        result_entry['train_time_s'] = round(train_time, 3)\n",
    "        results.append(result_entry)\n",
    "\n",
    "        print(f\"  -> Train Acc: {train_accuracy:.4f}, Val Acc: {val_accuracy:.4f}, Time: {train_time:.2f}s\")\n",
    "\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    metric_cols = ['train_accuracy', 'val_accuracy', 'train_time_s']\n",
    "    param_cols = list(param_grid.keys())\n",
    "    # Ensure all expected columns are present before reordering\n",
    "    final_cols = param_cols + [col for col in metric_cols if col in results_df.columns]\n",
    "    results_df = results_df[final_cols]\n",
    "\n",
    "\n",
    "    results_df = results_df.sort_values(by='val_accuracy', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    print(\"\\nHyperparameter analysis complete.\")\n",
    "    return results_df\n",
    "\n",
    "print(\"Generating synthetic data for example...\")\n",
    "X, y = make_classification(n_samples=1500, n_features=25, n_informative=15,\n",
    "                           n_redundant=5, n_classes=2, random_state=42, flip_y=0.05)\n",
    "X = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(X.shape[1])])\n",
    "y = pd.Series(y, name='target')\n",
    "\n",
    "print(\"Splitting data...\")\n",
    "X_train_ex, X_val_ex, y_train_ex, y_val_ex = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y \n",
    ")\n",
    "print(f\"Train set size: {X_train_ex.shape[0]}, Validation set size: {X_val_ex.shape[0]}\")\n",
    "\n",
    "\n",
    "n_estimators_to_try = [50, 100]       \n",
    "max_depth_to_try = [5, 10, None]     \n",
    "max_features_to_try = ['sqrt', 0.6]   \n",
    "min_samples_split_to_try = [2, 8]     \n",
    "min_samples_leaf_to_try = [1, 4]     \n",
    "criterion_to_try = ['gini', 'entropy']\n",
    "\n",
    "analysis_results = analyze_random_forest_hyperparameters(\n",
    "    X_train=X_train_ex,\n",
    "    y_train=y_train_ex,\n",
    "    X_val=X_val_ex,\n",
    "    y_val=y_val_ex,\n",
    "    n_estimators_list=n_estimators_to_try,\n",
    "    max_depth_list=max_depth_to_try,\n",
    "    max_features_list=max_features_to_try,\n",
    "    min_samples_split_list=min_samples_split_to_try,\n",
    "    min_samples_leaf_list=min_samples_leaf_to_try,\n",
    "    criterion_list=criterion_to_try,\n",
    "    bootstrap_list=[True], \n",
    "    random_state=42,\n",
    "    n_jobs=-1 \n",
    ")\n",
    "\n",
    "print(\"\\n--- Hyperparameter Analysis Results ---\")\n",
    "print(analysis_results.head(10))\n",
    "\n",
    "print(\"\\n--- Best Hyperparameter Combination Found ---\")\n",
    "if not analysis_results.empty:\n",
    "    print(analysis_results.iloc[0])\n",
    "else:\n",
    "    print(\"No results generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "c533e49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>criterion</th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>train_time_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>gini</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.90444</td>\n",
       "      <td>0.188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>gini</td>\n",
       "      <td>True</td>\n",
       "      <td>0.99429</td>\n",
       "      <td>0.90444</td>\n",
       "      <td>0.189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>10.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>gini</td>\n",
       "      <td>True</td>\n",
       "      <td>0.98000</td>\n",
       "      <td>0.90222</td>\n",
       "      <td>0.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>10.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>gini</td>\n",
       "      <td>True</td>\n",
       "      <td>0.98000</td>\n",
       "      <td>0.90222</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>gini</td>\n",
       "      <td>True</td>\n",
       "      <td>0.99333</td>\n",
       "      <td>0.90222</td>\n",
       "      <td>0.184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>gini</td>\n",
       "      <td>True</td>\n",
       "      <td>0.93619</td>\n",
       "      <td>0.86444</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>gini</td>\n",
       "      <td>True</td>\n",
       "      <td>0.93905</td>\n",
       "      <td>0.86222</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>entropy</td>\n",
       "      <td>True</td>\n",
       "      <td>0.93905</td>\n",
       "      <td>0.86222</td>\n",
       "      <td>0.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>entropy</td>\n",
       "      <td>True</td>\n",
       "      <td>0.93048</td>\n",
       "      <td>0.86000</td>\n",
       "      <td>0.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>entropy</td>\n",
       "      <td>True</td>\n",
       "      <td>0.93048</td>\n",
       "      <td>0.86000</td>\n",
       "      <td>0.098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_estimators  max_depth max_features  min_samples_split  min_samples_leaf  \\\n",
       "0            100        NaN          0.6                  2                 1   \n",
       "1            100        NaN          0.6                  8                 1   \n",
       "2            100       10.0         sqrt                  2                 4   \n",
       "3            100       10.0         sqrt                  8                 4   \n",
       "4            100       10.0          0.6                  8                 1   \n",
       "..           ...        ...          ...                ...               ...   \n",
       "91            50        5.0         sqrt                  8                 4   \n",
       "92            50        5.0         sqrt                  8                 1   \n",
       "93            50        5.0          0.6                  2                 1   \n",
       "94            50        5.0          0.6                  2                 4   \n",
       "95            50        5.0          0.6                  8                 4   \n",
       "\n",
       "   criterion  bootstrap  train_accuracy  val_accuracy  train_time_s  \n",
       "0       gini       True         1.00000       0.90444         0.188  \n",
       "1       gini       True         0.99429       0.90444         0.189  \n",
       "2       gini       True         0.98000       0.90222         0.135  \n",
       "3       gini       True         0.98000       0.90222         0.125  \n",
       "4       gini       True         0.99333       0.90222         0.184  \n",
       "..       ...        ...             ...           ...           ...  \n",
       "91      gini       True         0.93619       0.86444         0.072  \n",
       "92      gini       True         0.93905       0.86222         0.072  \n",
       "93   entropy       True         0.93905       0.86222         0.101  \n",
       "94   entropy       True         0.93048       0.86000         0.108  \n",
       "95   entropy       True         0.93048       0.86000         0.098  \n",
       "\n",
       "[96 rows x 10 columns]"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890d644c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
